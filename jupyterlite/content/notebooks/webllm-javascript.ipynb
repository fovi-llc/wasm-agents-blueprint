{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5bd448",
   "metadata": {},
   "source": [
    "# WebLLM from JavaScript (JupyterLite)\n",
    "\n",
    "This notebook uses the JavaScript kernel to talk to a WebLLM worker directly from the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(async () => {\n",
    "  if (!globalThis.webllmHelpers) {\n",
    "    const workerSource = `\n",
    "      import { WebWorkerMLCEngineHandler } from 'https://esm.run/@mlc-ai/web-llm';\n",
    "      const handler = new WebWorkerMLCEngineHandler();\n",
    "      self.onmessage = (msg) => handler.onmessage(msg);\n",
    "    `;\n",
    "    const module = await import('https://esm.run/@mlc-ai/web-llm');\n",
    "    const workerURL = URL.createObjectURL(new Blob([workerSource], { type: 'application/javascript' }));\n",
    "    globalThis.webllmHelpers = {\n",
    "      module,\n",
    "      workerURL,\n",
    "      async createEngine(model, options = {}) {\n",
    "        const worker = new Worker(workerURL, { type: 'module' });\n",
    "        return await module.CreateWebWorkerMLCEngine(worker, model, options);\n",
    "      },\n",
    "      async chat(engine, request) {\n",
    "        return await engine.chat.completions.create(request);\n",
    "      },\n",
    "      async stream(engine, request, callbacks = {}) {\n",
    "        const stream = await engine.chat.completions.create({ ...request, stream: true });\n",
    "        for await (const chunk of stream) {\n",
    "          callbacks.onChunk?.(chunk);\n",
    "        }\n",
    "        return await engine.getMessage();\n",
    "      }\n",
    "    };\n",
    "    console.log('WebLLM helpers initialised.');\n",
    "  } else {\n",
    "    console.log('WebLLM helpers already available.');\n",
    "  }\n",
    "})();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f4cc8",
   "metadata": {},
   "source": [
    "Create an engine that runs the chat model inside a Web Worker. Progress messages show download status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "const engine = await webllmHelpers.createEngine('SmolLM2-360M-Instruct-q0f16-MLC', {\n",
    "  initProgressCallback(report) {\n",
    "    console.log(report.text);\n",
    "  },\n",
    "});\n",
    "engine;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac4cce",
   "metadata": {},
   "source": [
    "Call the OpenAI-compatible chat API without streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const response = await webllmHelpers.chat(engine, {\n",
    "  messages: [\n",
    "    { role: 'system', content: 'You are a succinct assistant living in a Web Worker.' },\n",
    "    { role: 'user', content: 'Name three perks of browser-based LLMs.' }\n",
    "  ],\n",
    "  temperature: 0.3,\n",
    "  max_tokens: 128\n",
    "});\n",
    "console.log(response.choices[0].message.content);\n",
    "response;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940abd4",
   "metadata": {},
   "source": [
    "Stream tokens as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9010a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "let streamed = '';\n",
    "await webllmHelpers.stream(engine, {\n",
    "  messages: [\n",
    "    { role: 'system', content: 'Compose poetry with a playful tone.' },\n",
    "    { role: 'user', content: 'Write a limerick about WebLLM notebooks.' }\n",
    "  ],\n",
    "  temperature: 0.6,\n",
    "  max_tokens: 128,\n",
    "  stream_options: { include_usage: true }\n",
    "}, {\n",
    "  onChunk(chunk) {\n",
    "    const delta = chunk.choices?.[0]?.delta?.content ?? '';\n",
    "    if (delta) {\n",
    "      streamed += delta;\n",
    "      console.log(delta);\n",
    "    }\n",
    "  }\n",
    "});\n",
    "streamed;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "javascript"
   },
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "nbconvert_exporter": "javascript",
   "pygments_lexer": "javascript",
   "version": "es2023"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
